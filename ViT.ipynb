{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "x4OO0bZH35nG"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "from torch.nn import functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFOONGdD5pFM"
      },
      "outputs": [],
      "source": [
        "hyper_par = {\n",
        "    \"patch_size\": 1,  \n",
        "    \"embed_dim\": 128,\n",
        "    \"num_hidden_layers\": 1,\n",
        "    \"num_attn_heads\": 1,\n",
        "    \"hidden_dropout_prob\": 0.0,\n",
        "    \"attn_probs_dropout_prob\": 0.0,\n",
        "    \"image_size\": 1600,\n",
        "    \"num_classes\": 2, \n",
        "    \"num_channels\": 1,\n",
        "    \"qkv_bias\": True,\n",
        "    'batch_size':32,\n",
        "    'lr':0.001,\n",
        "    'epochs':10,\n",
        "}\n",
        "\n",
        "BATCH_SIZE=hyper_par['batch_size']\n",
        "\n",
        "with open(\"..\\Ising2DFM_reSample_L40_T=All.pkl\", 'rb') as f:\n",
        "    data= pickle.load(f)\n",
        "\n",
        "\n",
        "data=np.unpackbits(data).astype(int).reshape(-1,1600)\n",
        "data=np.reshape(data,(160000,40,40))\n",
        "transform = transforms.Compose(\n",
        "        [transforms.ToTensor()])\n",
        "for i in range(len(data)):\n",
        "    data[i]=transform(np.asarray(data[i]))\n",
        "\n",
        "data=np.expand_dims(data,1)\n",
        "\n",
        "with open(\"..\\Ising2DFM_reSample_L40_T=All_labels.pkl\", 'rb') as f:\n",
        "    labels= pickle.load(f)\n",
        "\n",
        "\n",
        "\n",
        "labels=torch.from_numpy(labels)\n",
        "data=torch.from_numpy(data).float()\n",
        "\n",
        "\n",
        "dataset=torch.utils.data.TensorDataset(data,labels)\n",
        "\n",
        "train_dataset,test_dataset=train_test_split(dataset)\n",
        "\n",
        "train_loader=torch.utils.data.DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
        "test_loader=torch.utils.data.DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2O_hq2Jt8BHe"
      },
      "outputs": [],
      "source": [
        "#The model\n",
        "\n",
        "class Patch_Embed(nn.Module):\n",
        "\n",
        "    def __init__(self, hyper_par):\n",
        "        super().__init__()\n",
        "        self.image_size = hyper_par[\"image_size\"]\n",
        "        self.patch_size = hyper_par[\"patch_size\"]\n",
        "        self.num_channels = hyper_par[\"num_channels\"]\n",
        "        self.embed_dim = hyper_par[\"embed_dim\"]\n",
        "   \n",
        "        self.num_patches = (self.image_size) // (self.patch_size) ** 2\n",
        "\n",
        "        self.projection = nn.Conv2d(self.num_channels, self.embed_dim, kernel_size=self.patch_size, stride=self.patch_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "       # (batch_size, num_channels, image_size, image_size) -> (batch_size, num_patches, embed_dim)\n",
        "        x = self.projection(x)\n",
        "        x = x.flatten(2).transpose(1, 2)\n",
        "        return x\n",
        "class Pos_Embed(nn.Module):\n",
        "    def __init__(self,embed_dim,max_len=2000):\n",
        "        super(Pos_Embed,self).__init__()\n",
        "\n",
        "        self.embed_dim=embed_dim\n",
        "        pe=torch.zeros(max_len,embed_dim)\n",
        "        position=torch.arange(0,max_len).unsqueeze(1)\n",
        "        div_term=torch.exp(torch.arange(0,embed_dim,2)*-(math.log(10000.0)/embed_dim))\n",
        "        \n",
        "        pe[:,0::2]=torch.sin(position*div_term)\n",
        "        pe[:,1::2]=torch.cos(position*div_term)\n",
        "        pe=pe.unsqueeze(0)\n",
        "\n",
        "        self.register_buffer('pe',pe)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=x+self.pe[:,:x.size(1)]\n",
        "        return x\n",
        "\n",
        "class Embeddings(nn.Module):\n",
        "        \n",
        "    def __init__(self, hyper_par):\n",
        "        super().__init__()\n",
        "        self.hyper_par = hyper_par\n",
        "        self.patch_embeddings = Patch_Embed(hyper_par)\n",
        "        # Creating a learnable [CLS] token\n",
        "        \n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, hyper_par[\"embed_dim\"]))\n",
        "     \n",
        "        \n",
        "        # self.position_embeddings = nn.Parameter(torch.randn(1, self.patch_embeddings.num_patches + 1, hyper_par[\"embed_dim\"]))\n",
        "        self.position_embeddings=Pos_Embed(hyper_par[\"embed_dim\"])\n",
        "        self.dropout = nn.Dropout(hyper_par[\"hidden_dropout_prob\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_embeddings(x)\n",
        "        # x = self.patch_embeddings #for learnable encoding\n",
        "        batch_size, _, _ = x.size()\n",
        "        # Expanding the [CLS] token to the batch size\n",
        "        \n",
        "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n",
        "     \n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        x = x + self.position_embeddings(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class MultiHeadAttn(nn.Module):\n",
        "\n",
        "    def __init__(self, hyper_par):\n",
        "        super().__init__()\n",
        "        self.embed_dim = hyper_par[\"embed_dim\"]\n",
        "        self.num_attn_heads = hyper_par[\"num_attn_heads\"]\n",
        "  \n",
        "        self.attn_head_size = self.embed_dim // self.num_attn_heads\n",
        "    \n",
        "        self.qkv_bias = hyper_par[\"qkv_bias\"]\n",
        "\n",
        "        # Creating a linear layer to project the query, key, and value\n",
        "        self.qkv_projection = nn.Linear(self.embed_dim, self.embed_dim * 3, bias=self.qkv_bias)\n",
        "\n",
        "        self.attn_dropout = nn.Dropout(hyper_par[\"attn_probs_dropout_prob\"])\n",
        "\n",
        "        # Creating a linear layer to project the attn output back to the hidden size\n",
        "        self.output_projection = nn.Linear(self.embed_dim, self.embed_dim)\n",
        "        self.output_dropout = nn.Dropout(hyper_par[\"hidden_dropout_prob\"])\n",
        "\n",
        "    def forward(self, x, output_attns=False):\n",
        "\n",
        "        # (batch_size, sequence_length, embed_dim) -> (batch_size, sequence_length, embed_dim * 3)\n",
        "        qkv = self.qkv_projection(x)\n",
        "    \n",
        "        # (batch_size, sequence_length, embed_dim* 3) -> (batch_size, sequence_length, embed_dim)\n",
        "        query, key, value = torch.chunk(qkv, 3, dim=-1)\n",
        "        # Resizing the query, key, and value to (batch_size, num_attn_heads, sequence_length, attn_head_size)\n",
        "        batch_size, sequence_length, _ = query.size()\n",
        "        query = query.view(batch_size, sequence_length, self.num_attn_heads, self.attn_head_size).transpose(1, 2)\n",
        "        key = key.view(batch_size, sequence_length, self.num_attn_heads, self.attn_head_size).transpose(1, 2)\n",
        "        # key=query\n",
        "        value = value.view(batch_size, sequence_length, self.num_attn_heads, self.attn_head_size).transpose(1, 2)\n",
        "        # Calculating the attn scores\n",
        "\n",
        "        attn_scores = torch.matmul(query, key.transpose(-1, -2))/ math.sqrt(self.attn_head_size)\n",
        "    \n",
        "        attn_probs = self.attn_dropout(nn.functional.softmax(attn_scores, dim=-1))\n",
        "\n",
        "        # Calculating the attn output\n",
        "        attn_output = torch.matmul(attn_probs, value)\n",
        "\n",
        "        #  (batch_size, num_attn_heads, sequence_length, attn_head_size)-> (batch_size, sequence_length, embed_dim)\n",
        "        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, sequence_length, self.embed_dim)\n",
        "        \n",
        "        # Project the attn output back to the embed_dim\n",
        "        attn_output = self.output_dropout(self.output_projection(attn_output))\n",
        "  \n",
        "    \n",
        "        if not output_attns:\n",
        "            return (attn_output, None)\n",
        "        else:\n",
        "            return (attn_output, attn_probs)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "    def __init__(self, hyper_par):\n",
        "        super().__init__()\n",
        "        self.lin_1 = nn.Linear(hyper_par[\"embed_dim\"], hyper_par[\"embed_dim\"])\n",
        "        self.activation = nn.GELU()\n",
        "        self.lin_2 = nn.Linear(hyper_par[\"embed_dim\"], hyper_par[\"embed_dim\"])\n",
        "        self.dropout = nn.Dropout(hyper_par[\"hidden_dropout_prob\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin_1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.lin_2(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, hyper_par):\n",
        "        super().__init__()\n",
        "        self.attn = MultiHeadAttn(hyper_par)\n",
        "        self.layernorm_1 = nn.LayerNorm(hyper_par[\"embed_dim\"])\n",
        "        self.mlp = MLP(hyper_par)\n",
        "        self.layernorm_2 = nn.LayerNorm(hyper_par[\"embed_dim\"])\n",
        "\n",
        "    def forward(self, x, output_attns=False):\n",
        "        \n",
        "        attn_output, attn_probs = self.attn(self.layernorm_1(x), output_attns=output_attns)\n",
        "\n",
        "        x = x + attn_output\n",
        "        # Feed-forward network\n",
        "        mlp_output = self.mlp(self.layernorm_2(x))\n",
        "   \n",
        "        x = x + mlp_output\n",
        "\n",
        "        if not output_attns:\n",
        "            return (x, None)\n",
        "        else:\n",
        "            return (x, attn_probs)\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, hyper_par):\n",
        "        super().__init__()\n",
        "        # Creating a list of transformer blocks\n",
        "        self.blocks = nn.ModuleList([])\n",
        "        for _ in range(hyper_par[\"num_hidden_layers\"]):\n",
        "            block = TransformerBlock(hyper_par)\n",
        "            self.blocks.append(block)\n",
        "\n",
        "    def forward(self, x, output_attns=False):\n",
        "        # Calculating the transformer block's output for each block\n",
        "        all_attns = []\n",
        "        for block in self.blocks:\n",
        "            x, attn_probs = block(x, output_attns=output_attns)\n",
        "            if output_attns:\n",
        "                all_attns.append(attn_probs)\n",
        "        # Returning the encoder's output and the attn probabilities\n",
        "        if not output_attns:\n",
        "            return (x, None)\n",
        "        else:\n",
        "            return (x, all_attns)\n",
        "\n",
        "class ViT(nn.Module):\n",
        "\n",
        "    def __init__(self, hyper_par):\n",
        "        super().__init__()\n",
        "        self.hyper_par = hyper_par\n",
        "        self.image_size = hyper_par[\"image_size\"]\n",
        "        self.embed_dim = hyper_par[\"embed_dim\"]\n",
        "        self.num_classes = hyper_par[\"num_classes\"]\n",
        "     \n",
        "        self.embedding = Embeddings(hyper_par)\n",
        "\n",
        "        self.encoder = Encoder(hyper_par)\n",
        "        # Creating a linear layer to project the encoder's output to the number of classes\n",
        "        self.classifier = nn.Linear(self.embed_dim, self.num_classes)\n",
        "\n",
        "    def forward(self, x, output_attns=False):\n",
        " \n",
        "        embedding_output = self.embedding(x)\n",
        "\n",
        "        encoder_output, all_attns = self.encoder(embedding_output, output_attns=output_attns)\n",
        "        # Calculating the logits, take the [CLS] token's output as features for classification\n",
        "        logits = self.classifier(encoder_output[:, 0, :])\n",
        "\n",
        "        if not output_attns:\n",
        "            return (logits, None)\n",
        "        else:\n",
        "            return (logits, all_attns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiLJR8fh_xao"
      },
      "outputs": [],
      "source": [
        "#Functions to save the model and visualize the results\n",
        "\n",
        "def save_experiment(experiment_name, hyper_par, model, train_losses, test_losses, accuracies, base_dir=\"experiments\"):\n",
        "    outdir = os.path.join(base_dir, experiment_name)\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "    \n",
        "    # Save the hyper_par\n",
        "    hyper_parfile = os.path.join(outdir, 'hyper_par.json')\n",
        "    with open(hyper_parfile, 'w') as f:\n",
        "        json.dump(hyper_par, f, sort_keys=True, indent=4)\n",
        "    \n",
        "    # Save the metrics\n",
        "    jsonfile = os.path.join(outdir, 'metrics.json')\n",
        "    with open(jsonfile, 'w') as f:\n",
        "        data = {\n",
        "            'train_losses': train_losses,\n",
        "            'test_losses': test_losses,\n",
        "            'accuracies': accuracies,\n",
        "        }\n",
        "        json.dump(data, f, sort_keys=True, indent=4)\n",
        "    \n",
        "    # Save the model\n",
        "    save_checkpoint(experiment_name, model, \"final\", base_dir=base_dir)\n",
        "\n",
        "def save_checkpoint(experiment_name, model, epoch, base_dir=\"experiments\"):\n",
        "    outdir = os.path.join(base_dir, experiment_name)\n",
        "    os.makedirs(outdir, exist_ok=True)\n",
        "    cpfile = os.path.join(outdir, f'model_{epoch}.pt')\n",
        "    torch.save(model.state_dict(), cpfile)\n",
        "\n",
        "def load_experiment(experiment_name, checkpoint_name=\"model_final.pt\", base_dir=\"experiments\"):\n",
        "    outdir = os.path.join(base_dir, experiment_name)\n",
        "    # Load the hyper_par\n",
        "    hyper_parfile = os.path.join(outdir, 'hyper_par.json')\n",
        "    with open(hyper_parfile, 'r') as f:\n",
        "        hyper_par = json.load(f)\n",
        "    # Load the metrics\n",
        "    jsonfile = os.path.join(outdir, 'metrics.json')\n",
        "    with open(jsonfile, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    train_losses = data['train_losses']\n",
        "    test_losses = data['test_losses']\n",
        "    accuracies = data['accuracies']\n",
        "    # Load the model\n",
        "    model = ViT(hyper_par)\n",
        "    cpfile = os.path.join(outdir, checkpoint_name)\n",
        "    model.load_state_dict(torch.load(cpfile))\n",
        "    return hyper_par, model, train_losses, test_losses, accuracies\n",
        "\n",
        "\n",
        "\n",
        "shape=40\n",
        "@torch.no_grad()\n",
        "def visualize_attn(model, output=None):\n",
        "    seed=32\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "    model.eval()\n",
        "    # Load random images\n",
        "    num_images = 30\n",
        "    testset = test_dataset\n",
        "    classes = ('Disordered Phase','Ordered Phase')\n",
        "\n",
        "\n",
        "    indices = torch.randperm(len(testset))[:num_images]\n",
        "    raw_images = [np.asarray(testset[i][0]) for i in indices]\n",
        "   \n",
        "    labels = [testset[i][1] for i in indices]\n",
        "    # Convert the images to tensors\n",
        "    test_transform = transforms.Compose(\n",
        "        [transforms.ToTensor()])\n",
        "    images = torch.stack([test_transform(image) for image in raw_images])\n",
        "    images = np.reshape(images,(num_images,1,shape,shape))\n",
        "\n",
        "   \n",
        "    device= \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    images = images.to(device)\n",
        "    model = model.to(device)\n",
        "    # Get the attn maps from the last block\n",
        "    logits, attn_maps = model(images, output_attns=True)\n",
        "    # Get the predictions\n",
        "    predictions = torch.argmax(logits, dim=1)\n",
        "    # Concatenate the attn maps from all blocks\n",
        "    attn_maps = torch.cat(attn_maps, dim=1)\n",
        "    # selecting  the attn maps of the CLS token\n",
        "    attn_maps = attn_maps[:, :, 0, 1:]\n",
        "    # Then average the attn maps of the CLS token over all the heads\n",
        "    attn_maps = attn_maps.mean(dim=1)\n",
        "\n",
        "    num_patches = attn_maps.size(-1)\n",
        "    size = int(math.sqrt(num_patches))\n",
        "    attn_maps = attn_maps.view(-1, size, size)\n",
        "    # Resizing the map to the size of the image\n",
        "    attn_maps = attn_maps.unsqueeze(1)\n",
        "    attn_maps = F.interpolate(attn_maps, size=(40, 40), mode='bilinear', align_corners=False)\n",
        "    attn_maps = attn_maps.squeeze(1)\n",
        "\n",
        "    # Ploting the images and the attn maps\n",
        "    fig = plt.figure(figsize=(40, 20))\n",
        "    mask = np.concatenate([np.ones((shape, shape)), np.zeros((shape,shape))], axis=1)\n",
        "    for i in range(num_images):\n",
        "        raw_images[i] = np.reshape(raw_images[i],(shape,shape,1))\n",
        "        ax = fig.add_subplot(6, 5, i+1, xticks=[], yticks=[])\n",
        "        img = np.concatenate((raw_images[i][:,:,0], raw_images[i][:,:,0]), axis=1)\n",
        "        ax.imshow(img,cmap='gray')\n",
        "        # Mask out the attn map of the left image\n",
        "        extended_attn_map = np.concatenate((np.zeros((shape, shape)), attn_maps[i].cpu()), axis=1)\n",
        "        extended_attn_map = np.ma.masked_where(mask==1, extended_attn_map)\n",
        "        ax.imshow(extended_attn_map, alpha=0.5, cmap='jet')\n",
        "        # Show the ground truth and the prediction\n",
        "        gt = classes[labels[i]]\n",
        "        pred = classes[predictions[i]]\n",
        "        ax.set_title(f\"{gt}                       attn map:{pred}\", color=(\"green\" if gt==pred else \"red\"))\n",
        "    if output is not None:\n",
        "        plt.savefig(output)\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "def plot_image_patches(image, patch_size, stride,output_file=None):\n",
        "\n",
        "    height, width,_ = image.shape\n",
        "    patches = []\n",
        "\n",
        "    # Extract patches from the image\n",
        "    for y in range(0, height - patch_size + 1, stride):\n",
        "        for x in range(0, width - patch_size + 1, stride):\n",
        "            patch = image[y:y+patch_size, x:x+patch_size]\n",
        "            patches.append(patch)\n",
        "\n",
        "    num_patches = len(patches)\n",
        "\n",
        "    # Determine the number of rows and columns for subplots\n",
        "    num_cols = int(np.ceil(np.sqrt(num_patches)))\n",
        "    num_rows = int(np.ceil(num_patches / num_cols))\n",
        "\n",
        "    # Create subplots to display the patches\n",
        "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(10, 10))\n",
        "  \n",
        "    for i, ax in enumerate(axs.flat):\n",
        "        if i < num_patches:\n",
        "            ax.imshow(patches[i], cmap='jet',vmin=np.min(np.asarray(image)), vmax=np.max(np.asarray(image)))\n",
        "#             ax.imshow(patches[i], cmap='jet')\n",
        "\n",
        "            ax.axis('off')\n",
        "\n",
        "            # Writing pixel values on each patch\n",
        "            height, width,_ = patches[i].shape\n",
        "            for y in range(height):\n",
        "                for x in range(width):\n",
        "                    ax.text(x, y,str(np.round(float(10000*patches[i][y, x]),2)), color='black', fontsize=6,\n",
        "                            ha='center', va='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    \n",
        "\n",
        "    # Save the image as PNG if the output file path is provided\n",
        "    if output_file:\n",
        "        plt.savefig(output_file, dpi=300,bbox_inches='tight')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "@torch.no_grad()  \n",
        "def  patch_attn(model):\n",
        "    \n",
        "    model.eval()\n",
        "    # Load random images\n",
        "    num_images = 1\n",
        "    testset = test_dataset\n",
        "    classes = ('Disordered Phase','Ordered Phase')\n",
        "\n",
        "\n",
        "    indices = torch.randperm(len(testset))[:num_images]\n",
        "    raw_images = np.asarray(testset[indices][0]) \n",
        "   \n",
        "    label = testset[indices][1]\n",
        "    label = classes[label]\n",
        "    # Convert the images to tensors\n",
        "    test_transform = transforms.Compose(\n",
        "        [transforms.ToTensor()])\n",
        "    images = test_transform(raw_images)\n",
        "    images = np.reshape(images,(num_images,1,40,40))\n",
        "\n",
        "    device= \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    images = images.to(device)\n",
        "    model = model.to(device)\n",
        "    # Get the attention maps from the last block\n",
        "    logits, attention_maps = model(images, output_attentions=True)\n",
        "\n",
        "    predictions = torch.argmax(logits, dim=1)\n",
        "    \n",
        "    attention_maps = torch.cat(attention_maps, dim=1)\n",
        "    # selecting only the attention maps of the CLS token\n",
        "    attention_maps = attention_maps[:, :, 0, 1:]\n",
        "    # Then average the attention maps of the CLS token over all the heads\n",
        "    attention_maps = attention_maps.mean(dim=1)\n",
        "\n",
        "    num_patches = attention_maps.size(-1)\n",
        "    size = int(math.sqrt(num_patches))\n",
        "    attention_maps = attention_maps.view(-1, size, size)\n",
        "\n",
        "\n",
        "    attn_map=np.reshape(attention_maps.cpu(),(40,40,1))\n",
        "    plot_image_patches(np.assarray(attn_map),20,20,label,\"patch_attn.png\")\n",
        "    gt = classes[labels]\n",
        "    pred = classes[predictions]\n",
        "    print(f\"Ground Truth:{gt}\",f\"Prediction: {pred}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "\n",
        "    def __init__(self, model, optimizer, loss_fn, exp_name, device):\n",
        "        self.model = model.to(device)\n",
        "        self.optimizer = optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "        self.exp_name = exp_name\n",
        "        self.device = device\n",
        "\n",
        "    def train(self, trainloader, testloader, epochs, save_model_every_n_epochs=0):\n",
        "   \n",
        "        # Keeping track of the losses and accuracies\n",
        "        train_losses, test_losses, accuracies = [], [], []\n",
        "        # Training the model\n",
        "        for i in range(epochs):\n",
        "            train_loss = self.train_epoch(trainloader)\n",
        "            accuracy, test_loss = self.evaluate(testloader)\n",
        "            train_losses.append(train_loss)\n",
        "            test_losses.append(test_loss)\n",
        "            accuracies.append(accuracy)\n",
        "            print(f\"Epoch: {i+1}, Train loss: {train_loss:.4f}, Test loss: {test_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "            if save_model_every_n_epochs > 0 and (i+1) % save_model_every_n_epochs == 0 and i+1 != epochs:\n",
        "                print('\\tSave checkpoint at epoch', i+1)\n",
        "                save_checkpoint(self.exp_name, self.model, i+1)\n",
        "        # Save the experiment\n",
        "        save_experiment(self.exp_name, hyper_par, self.model, train_losses, test_losses, accuracies)\n",
        "\n",
        "    def train_epoch(self, trainloader):\n",
        "        \n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        for batch in trainloader:\n",
        "            # Move the batch to the device\n",
        "            batch = [t.to(self.device) for t in batch]\n",
        "            images, labels = batch\n",
        "            # Zero the gradients\n",
        "            self.optimizer.zero_grad()\n",
        "            # Calculate the loss\n",
        "            loss = self.loss_fn(self.model(images)[0], labels)\n",
        "            # Backpropagate the loss\n",
        "            loss.backward()\n",
        "            # Update the model's parameters\n",
        "            self.optimizer.step()\n",
        "            total_loss += loss.item() * len(images)\n",
        "        return total_loss / len(trainloader.dataset)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def evaluate(self, testloader):\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in testloader:\n",
        "                # Move the batch to the device\n",
        "                batch = [t.to(self.device) for t in batch]\n",
        "                images, labels = batch\n",
        "                \n",
        "                # Get predictions\n",
        "                logits, _ = self.model(images)\n",
        "\n",
        "                # Calculate the loss\n",
        "                loss = self.loss_fn(logits, labels)\n",
        "                total_loss += loss.item() * len(images)\n",
        "\n",
        "                # Calculate the accuracy\n",
        "                predictions = torch.argmax(logits, dim=1)\n",
        "                correct += torch.sum(predictions == labels).item()\n",
        "        accuracy = correct / len(testloader.dataset)\n",
        "        avg_loss = total_loss / len(testloader.dataset)\n",
        "        return accuracy, avg_loss\n",
        "\n",
        "\n",
        "def main():\n",
        "  \n",
        "    batch_size = hyper_par['batch_size']\n",
        "    epochs = hyper_par['epochs']\n",
        "    lr = hyper_par['lr']\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    save_model_every_n_epochs = 5\n",
        "    # Load the dataset\n",
        "    trainloader,testloader=train_loader,test_loader\n",
        "    # Create the model, optimizer, loss function and trainer\n",
        "    model = ViT(hyper_par)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    trainer = Trainer(model, optimizer, loss_fn, 'my_exp', device=device)\n",
        "    trainer.train(trainloader, testloader, epochs, save_model_every_n_epochs=save_model_every_n_epochs)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hyper_par, model, train_losses, test_losses, accuracies = load_experiment(\"../experiments/my_exp\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "visualize_attn(model, \"attn.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "patch_attn(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "950rQnQ44wdV",
        "outputId": "a1dbc66e-6dd6-4a33-c179-7a8e0d5c4f90"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "ax1.plot(train_losses, label=\"Train loss\")\n",
        "ax1.plot(test_losses, label=\"Test loss\")\n",
        "\n",
        "ax1.set_xlabel(\"Epoch\")\n",
        "ax1.set_ylabel(\"Loss\")\n",
        "ax1.legend()\n",
        "ax2.plot(accuracies)\n",
        "ax2.set_xlabel(\"Epoch\")\n",
        "ax2.set_ylabel(\"Accuracy\")\n",
        "plt.savefig(\"metrics.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lr_Jb1NFd-el"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
